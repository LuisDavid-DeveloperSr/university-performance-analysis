{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U8aW7wOOaYS"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"https://www.uoc.edu/portal/system/modules/edu.uoc.presentations/resources/img/branding/logo-uoc-default.png\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">22.403 · Programació per a la ciència de dades</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Grau en Ciència de Dades Aplicada</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Informàtica, Multimèdia i Telecomunicació</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUs10ThXOaYU"
   },
   "source": [
    "Programación para la ciencia de datos - PEC4\n",
    "============================\n",
    "\n",
    "En este Notebook encontraréis el ejercicio que supone la cuarta y última actividad de evaluación continuada (PEC) de la asignatura. Esta PEC intenta presentaros un pequeño proyecto en el cual debéis resolver diferentes ejercicios, que  engloba muchos de los conceptos cubiertos durante la asignatura. \n",
    "\n",
    "El objetivo de este ejercicio será desarrollar un **paquete de Python** fuera del entorno de Notebooks, que nos permita resolver el problema dado. \n",
    "Trabajaréis en archivos Python planos `.py`. Este tendrá que incluir el correspondiente código organizado lógicamente (separado por módulos, organizados por funcionalidad,...), la documentación del código (*docstrings*) y tests. Además, tendréis que incluir los correspondientes archivos de documentación de alto nivel (`README`) así como los archivos de licencia y dependencias (`requirements.txt`) comentados en la teoría.\n",
    "\n",
    "Hacer un `setup.py` es opcional, pero si se hace se valorará positivamente de cara a la nota de la práctica y del curso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaEHGkzSOaYV"
   },
   "source": [
    "#Enunciado\n",
    "\n",
    "Queremos estudiar el comportamiento de la población de Estados Unidos respecto al uso de armas de fuego. Utilizaremos el siguiente dataset que ya ha sido incorporado en la carpeta del proyecto, proviente del siguiente enlace:\n",
    "* https://www.kaggle.com/datasets/pedropereira94/nics-firearm-background-checks\n",
    "\n",
    "El dataset representa la acumulación de información (por fecha y estado) de la verificación de antecedentes de gente que quiere sacarse el permiso de armas. Se quiere ver si se puede sacar algún tipo de conclusión sobre diferencias de estado, evolución temporal, etc.\n",
    "\n",
    "* la columna *permit* significa los permisos (verificación de antecedentes)\n",
    "* la columna *handgun* serían las peticiones de armas cortas (pistolas)\n",
    "* la columna *long_gun* serían las peticiones de armas largas\n",
    "\n",
    "Estas serán las columnas que nos interesan a parte del mes (*month*) y del estado (*state*).\n",
    "\n",
    "Además, en el ejercicio 5 utilizaremos también datos poblacionales para calcular los datos relativos. Para ello utilizaremos la siguiente dataset que también hemos incluido en el proyecto y que ha sido sacada de la siguiente dirección:\n",
    "* https://gist.githubusercontent.com/bradoyler/0fd473541083cfa9ea6b5da57b08461c/raw/fa5f59ff1ce7ad9ff792e223b9ac05c564b7c0fe/us-state-populations.csv \n",
    "\n",
    "El dataset presenta la población en el año 2014 de los diferentes estados ubicados en los Estados Unidos y contiene las siguientes columnas:\n",
    "\n",
    "* la columna *code*, un string de dos letras que identifica a cada uno de los estados (Por ejemplo Californa se identifica como CA y Florida como FL).\n",
    "* la columna *state* con el nombre del estado sin abreviar.\n",
    "* la columna *pop_2014*, representando el número de habitantes en el año 2014\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySGU4MKlPi9_"
   },
   "source": [
    "# Presentación de los resultados: \n",
    "\n",
    "Para hacer la entrega más fácil y homogénea os pedimos que organicéis el código de tal manera que **desde el fichero principal retorne todas las respuestas que se os pida en la PEC** haciendo uso de funciones que tendréis que definir en módulos.  Para eso, en cada ejercicio, os indicaremos el formato que tiene que tener cada respuesta, de tal manera que ejecutando `main.py` se vaya respondiendo a toda la PEC. Por defecto, `main.py` debe ejecutar todas las funciones de la PEC mostrando cómo funcionan pero también debe permitir ejecutarlas una a una si se desea. Debéis documentarlo todo muy bien en el README para que se pueda ejecutar sin problema. Os recordamos que en el README también tenéis que indicar como ejecutar los test y comprobar la cobertura de éstos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HmjDLEziV2n"
   },
   "source": [
    "### Ejercicio 1: Lectura y limpieza de datos. (0.75 puntos)\n",
    "\n",
    "\n",
    "#### Ejercicio 1.1. (0.25 puntos)\n",
    "\n",
    "Implementad una función llamada *read_csv* \n",
    "- **Inputs:** Los función recibirá como datos de entrada un único parámetro que será la url del fichero que queremos leer. \n",
    "- **Funcionalidad:** La función deberá ser capaz de leer el fichero csv *nics-firearm-background-checks*. Para comprobar que se han cargado correctamente esos datos. La función deberá mostrar por pantalla también las cinco primeras columnas de la base de datos así como también su estructura.\n",
    "- **Outputs:** La función devolverá una estructura de datos con el dataframe que se ha leido.\n",
    "\n",
    "\n",
    "#### Ejercicio 1.2. (0.25 puntos)\n",
    "\n",
    "Implementad una función llamada *clean_csv* \n",
    "- **Inputs:** Como datos de entrada la función recibirá la estructura de datos con el dataframe con todas sus columnas. \n",
    "- **Funcionalidad:** La función deberá ser capaz de limpiar el dataset inicial, eliminando así todas sus columnas excepto las cinco que utilizaremos a lo largo del ejercicio: *month, state, permit, handgun, long_gun*. Para aseguraros de que la función es correcta, se deberá mostrar por pantalla dentro de la misma el nombre de todas las columnas del dataframe.\n",
    "- **Outputs:** La función devolverá la estructura de datos con el dataframe conteniendo unicamente las siguientes columnas: *month, state, permit, handgun, long_gun.*\n",
    "\n",
    "\n",
    "#### Ejercicio 1.3. (0.25 puntos)\n",
    "\n",
    "Implementad una función llamada *rename_col* \n",
    "- **Inputs:** La estructura de datos con el dataframe con todas sus columnas. \n",
    "- **Funcionalidad:** La función deberá ser capaz cambiar el nombre de la columna *longgun* por *long_gun* Para aseguraros de que la función es correcta, nos debemos de asegurar de que esa columna efecitamente existe en el dataframe. Asimismo, deberemos mostrar por pantalla el nombre de todas las columnas del dataframe dentro de la misma función.\n",
    "- **Outputs:** La función devolverá la estructura de datos con el nombre de la columna cambiado.\n",
    "\n",
    "\n",
    "### Ejercicio 2: Procesamiento de datos. (1 punto)\n",
    "\n",
    "La información de la columna meses se encuentra por desgracia demasiado desglosada y con un formato que no es demasiado manejable. Por ejemplo Febrero del año 2020 aparecerá con este formato *2020-2* Así que tendremos que trabajar para solucionar este problema: \n",
    "\n",
    "#### Ejercicio 2.1. (0.5 puntos)\n",
    "\n",
    "Implementad una función llamada *breakdown_date* \n",
    "- **Inputs:** La función recibirá la estructura de datos con el dataframe conteniendo la columna *month* con el formato de datos igual que en el ejemplo. \n",
    "- **Funcionalidad:** La función dividirá la información que hay en la columna *month* creando dos nuevas columnas en el dataframe. Una de ellas llamada *year* y que contendrá el número del año y la otra columna llamada *month*. y que será el número del mes. Siguiendo nuestro antiguo ejemplo. Para el antiguo valor 2020-2, la columna year debería tener el valor **2020** y la columna month, deberá tener el valor **2**. Para asegurarnos de que la función es correcta, será necesario mostrar las cinco primeras filas del dataframe resultante.\n",
    "- **Outputs:** La estructura de datos con la información del mes dividida.\n",
    "\n",
    "\n",
    "#### Ejercicio 2.2. (0.5 puntos)\n",
    "\n",
    "Implementad una función llamada *erase_month* \n",
    "- **Inputs:** La función recibirá la estructura de datos con el dataframe conteniendo la columna *month* formado por un digito cuyo valor variará del 1 al 12. \n",
    "- **Funcionalidad:** Dado que la información sobre el mes está demasiado desglosada y con la información anualizada ya es suficiente, se pide crear una función que elimine la columna month. Para comprobar que se ha realizado correctamente, la función deberá mostrar por pantalla también las cinco primeras filas de datos y el nombre de todas sus columnas.\n",
    "- **Outputs:** La estructura de datos sin la columna *month*.\n",
    "\n",
    "\n",
    "### Ejercicio 3: Agrupamiento de datos. (1 punto)\n",
    "\n",
    "\n",
    "#### Ejercicio 3.1. (0.5 puntos)\n",
    "\n",
    "Implementad una función llamada *groupby_stateAndYear* \n",
    "- **Inputs:** La función recibirá la estructura de datos con el dataframe obtenido en el ejercicio 2.2. \n",
    "- **Funcionalidad:** La función deberá ser capaz de calcular los valores acumulados totales agrupando los datos por año y por estado: (columnas *year* y *sate*).\n",
    "- **Outputs:** La estructura de datos resultante con los datos agrupados.\n",
    "\n",
    "#### Ejercicio 3.2 (0.25 puntos)\n",
    "\n",
    "Implementad una función llamada *print_biggest_handguns* \n",
    "- **Inputs:** La función recibirá la estructura de datos con los datos agrupados por estado y por año como resultado del ejercicio 3.1. \n",
    "- **Funcionalidad:** La función deberá imprimir por pantalla un mensaje informativo indicando el nombre del estado y el año en donde se ha registrado un mayor numero de *hand_guns*.\n",
    "- **Outputs:** Esta función no devolverá ningún valor.\n",
    "\n",
    "#### Ejercicio 3.3 (0.25 puntos)\n",
    "\n",
    "Implementad una función llamada *print_biggest_longguns* \n",
    "- **Inputs:** La función recibirá la estructura de datos con los datos agrupados por estado y por año como resultado del ejercicio 3.1. \n",
    "- **Funcionalidad:** La función deberá imprimir por pantalla un mensaje informativo indicando el nombre del estado y el año en donde se ha registrado un mayor numero de *long_guns*.\n",
    "- **Outputs:** Esta función no devolverá ningún valor.\n",
    "\n",
    "\n",
    "### Ejercicio 4: Análisis temporal. (1 punto)\n",
    "\n",
    "Para este ejercicio se pedirá hacer un análisis temporal para ver la evolución de las licencias, pistolas y rifles de asalto a lo largo de los años. Para ello será necesario:\n",
    "\n",
    "#### Ejercicio 4.1. (0.75 puntos)\n",
    "\n",
    "Se pide crear un gráfico con las siguientes carácterísticas:\n",
    "- El eje X será el número del año (que en el caso de este dataframe debería variar desde 1998 hasta 2020), mientras que en el eje y se mostrarán tres series temporales con el número total de *permit* *hand_gun* y *long_gun* regirstrado por cada uno de los años\n",
    "\n",
    "\n",
    "\n",
    "#### Ejercicio 4.2. (0.25 puntos)\n",
    "\n",
    "Comenta el gráfico generado en el ejercicio 4.2. ¿Vemos una correlación en las licencias, pistolas y rifles de asalto a lo largo de los años? ¿Es la tendencia ascendente o descendente? ¿Ha habido cambios durante la pandemia? ¿Que podríamos esperar en los próximos años?\n",
    "\n",
    "**Nota**: En https://cnnespanol.cnn.com/2024/02/15/cultura-armas-estados-unidos-mundo-trax/ hay una gráfica sobre el número de víctimas de tiroteos masivos. En el 2017 hay un máximo, que parece coincidir con los resultados que habréis obtenido.\n",
    "\n",
    "\n",
    "### Ejercicio 5: Análisis de los estados (1.25 puntos)\n",
    "\n",
    "A lo largo de este ejercicio aplicaremos un poco de ciencia de datos y sacaremos una serie de conclusiones agrupando los datos por cada uno de los estados:\n",
    "\n",
    "#### Ejercicio 5.1 (0.25 puntos)\n",
    "\n",
    "Implementad una función llamada *groupby_state* \n",
    "- **Inputs:** La función recibirá la estructura de datos con los datos agrupados por estado y por año como resultado del ejercicio 3.1. \n",
    "- **Funcionalidad:** La función mostrará los valores totales agrupando los valores unicamente por estado y no por año. Para comprobar que la función es correctá se pedirá también que muestre por pantalla las 5 primeras filas del daraframe resultante.\n",
    "- **Outputs:** Esta función deberá devolver la estructura de datos con los valores agrupados unicamente por años.\n",
    "\n",
    "**Nota** Los resultados obtenidos en la función del ejercicio 5.1 nos muestran unicamente los valores absolutos. Sin embargo, también hay que tener en cuenta que no todos los estados son igual de poblados. Para establecer una comparación justa, deberíamos de tener en cuenta también la población total de cada estado, para calcular así los valores relativos. Para ello, utilizaremos un nuevo conjunto de datos que hemos obtenido de la siguiente dirección: https://gist.githubusercontent.com/bradoyler/0fd473541083cfa9ea6b5da57b08461c/raw/fa5f59ff1ce7ad9ff792e223b9ac05c564b7c0fe/us-state-populations.csv\n",
    "\n",
    "#### Ejercicio 5.2 (0.25 puntos)\n",
    "\n",
    "Los siguientes estados no aparecen en nuestro dataset anterior: (Guam, Mariana Islands, Puerto Rico y Virgin Islands). Por tanto, necesitaremos eliminarlos para poder continuar con nuestro análisis de datos.\n",
    "\n",
    "Implementad una función llamada *clean_states* \n",
    "- **Inputs:** La función recibirá la estructura de datos con los datos agrupados por estado como resultado del ejercicio 5.1. \n",
    "- **Funcionalidad:** La función primero comprobará si existen esos cuatro estados (Guam, Mariana Islands, Puerto Rico y Virgin Islands) y, en el caso de que existan lo eliminara. Para comprobar que la funcionalidad se ha implementado con exito, la función también mostrará por pantalla el número de estados diferentes.\n",
    "- **Outputs:** Esta función devolverá el mismo dataset pero sin los cuatro estados mencionados.\n",
    "\n",
    "#### Ejercicio 5.3 (0.25 puntos)\n",
    "\n",
    "Ahora nuestro objetivo será fusionar los dos datasets:\n",
    "\n",
    "Implementad una función llamada *merge_datasets* \n",
    "- **Inputs:** La función recibirá como parámetros de entrada, el conjunto de datos resultante del ejercicio ejercicio 5.2 y el conjunto de datos poblacionales provenientes del fichero: *us-state-populations*. (para leer los datos de la población puedes utilizar la función creada en el ejercicio 1.1) \n",
    "- **Funcionalidad:** La función fusionará los datos de los dos datasets recibidos como parámetros de entrada. Incluyendo por cada estado toda la información procedente de las dos fuentes de datos. Para comprobar que se ha hecho correctamente, la función imprimirá por pantalla las cinco primeras filas del dataset resultante.\n",
    "- **Outputs:** Esta función devolverá el dataset resultante al fusionar los datos.\n",
    "\n",
    "#### Ejercicio 5.4 (0.25 puntos)\n",
    "\n",
    "A continuación necesitaremos calcular los valores relativos:\n",
    "\n",
    "Implementad una función llamada *calculate_relative_values* \n",
    "- **Inputs:** La función recibirá como parámetros de entrada, el conjunto de datos resultante del ejercicio ejercicio 5.3.\n",
    "- **Funcionalidad:** La función creará 3 nuevas columnas llamadas *permit_perc*, *loggun_perc* y *shotgun_perc* (por si hay algún despistado que se confunda con la regla de tres como ya pasó con la PEC2 os voy a dar una pista, por ejemplo, en el caso de *permit_perc* los valores relativos se calcularían con la siguiente formula: (poblacionTotal * 100) / permit )\n",
    "- **Outputs:** Esta función devolverá el dataset resultante con las tres columnas nuevas: *permit_perc*, *loggun_perc* y *shotgun_perc* y los valores relativos ya calculados.\n",
    "\n",
    "#### Ejercicio 5.5 (0.25 puntos)\n",
    "\n",
    "1 - En primer lugar, calcularemos la media de permisos *permit_perc* con dos decimales y mostraremos el resultado en pantalla\n",
    "2 - En segundo lugar, mostraremos por pantalla toda la información relativa al estado de *Kentucky*\n",
    "\n",
    "**Nota** ¡Tenemos un problema técnico! El estado de *Kentucky* es lo que se llama un *outlier* o valor atípico. Los *outliers* son valores atípicamente altos que distorsionan cualquier tipo de métricas estadísticas. En este caso, la media está inflada debido a los valores que tiene este estado. Los *outliers* no solamente distorsionan las métricas estadísticas, también hacen que algoritmos de aprendizaje máquina lleguen a conclusiones erróneas y eso es un problema. Para solucionarlo, en este caso, podríamos calcular la mediana en lugar de la media. Eso ya estaría mucho menos distorsionado, pero, en este caso, optaremos por eliminar el estado *Kentucky* de nuestro dataset.\n",
    "\n",
    "3- Eliminar el estado de *Kentucky* de nuestro dataset.\n",
    "4- Volvermos a calcular la media con dos decimales.\n",
    "5- ¿Ha cambiado mucho el valor? ¿Entiendes el proceso de quitar valores atípicos? Escribe tus conclusiones.\n",
    "\n",
    "### Ejercicio 6: Mapas coropléticos (1.5 puntos)\n",
    "\n",
    "Geographic Data Science (GDS) es la rama de Ciencia de Datos que utiliza datos con información geográfica. En este enlace tienes disponible un curso de GDS, con un docker para que utilicéis los materiales (para cuando tengáis tiempo).\n",
    "\n",
    "Los mapas coropléticos son los mapas donde pintamos un área (estado, región, provincia, país) de un color, dentro de un mapa de colores, para obtener información visual.\n",
    "\n",
    "Vamos a hacer 3 mapas coropléticos para *permit_perc*, *handgun_perc* y *longgun_perc*. Hay diferentes soluciones. Proponemos hacerlo con el código disponible en:\n",
    "* https://python-graph-gallery.com/292-choropleth-map-with-folium/\n",
    "\n",
    "Para ello, vas a necesitar instalar las librerías folium y selenium.\n",
    "\n",
    "El fichero *us-states.json* contiene toda la información de las fronteras de los estados. Lo primero que puedes hacer es hacer funcionar el ejemplo que se propone (*US_Unemployment_Oct2012.csv*) y luego adaptarlo a la información que disponemos.\n",
    "\n",
    "Puedes generar 3 mapas (m1, m2 y m3), uno para cada variable. Luego estos mapas los puedes guardar a imagen con el siguiente código:\n",
    "<pre>\n",
    "import io\n",
    "from PIL import Image\n",
    "import selenium\n",
    "\n",
    "img_data = m._to_png(5)\n",
    "img = Image.open(io.BytesIO(img_data))\n",
    "img.save('imagen.png')\n",
    "</pre>\n",
    "\n",
    "Tienes que obtener 3 imágenes, una para cada variable que tienes (*permit_perc*, *handgun_perc* y *longgun_perc*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5L41AFTmOaYa"
   },
   "source": [
    "## Criterios de corrección\n",
    "\n",
    "Esta PEC se valorará siguiendo los siguientes criterios:\n",
    "\n",
    "* **Funcionalidad** (6.5 puntos): Se valorará que el código implemente todo lo que se pide.\n",
    "    * Ejercicio 1 (0.75 puntos)\n",
    "    * Ejercicio 2 (1 punto)\n",
    "    * Ejercicio 3 (1 punto)\n",
    "    * Ejercicio 4 (1 punto)\n",
    "    * Ejercicio 5 (1.25 puntos)\n",
    "    * Ejercicio 6 (1.5 puntos)\n",
    "\n",
    "* **Documentación** (0.5 puntos):  Todas las funciones de los ejercicios de esta PEC tendrán que estar debidamente documentadas utilizando docstrings (en el formato que prefiráis). \n",
    "* **Modularidad** (0.5 puntos): Se valorará la modularidad del código (tanto la organización del código en módulos como la creación de funciones). \n",
    "* **Estilo** (0.5 puntos): El código tiene que seguir la guía de estilo de Python (PEP8), exceptuando los casos donde hacerlo complique la legibilidad del código.\n",
    "* **Tests** (1.5 puntos): El código tiene que contener una o diversas *suites* de tests que permitan comprobar que el código funciona correctamente, con un mínimo del 50% de cobertura.\n",
    "* **Requeriments** (0.5 puntos): Tenéis que incluir un fichero de *requirements* que contenga la lista de librerías necesarias para ejecutar el código.\n",
    "* **README** y **licencia** (0.25 puntos): Tenéis que añadir también un fichero README, que presente el proyecto y explique cómo ejecutarlo, así como la inclusión de la licencia bajo la que se distribuye el código (podéis escoger la que queráis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8p8r2xwROaYb"
   },
   "source": [
    "### Importante\n",
    "\n",
    "**Nota 1**: De la misma manera que en las PECs anteriores, los criterios transversales se valorarán de manera proporcional a la parte de funcionalidad implementada.\n",
    "\n",
    "Por ejemplo, si el código sólo implementa la mitad de la PEC y la documentación está perfecta la puntuación correspondiente a documentación será de 0.25.\n",
    "\n",
    "**Nota 2**: Es imprescindible que el paquete que libréis se ejecute correctamente en la máquina virtual y que el fichero de REAMDE explique claramente cómo ejecutar el código para generar los resultados pedidos. Además en el README tiene que explicarse también cómo se ejecutarán los test y cómo se comprueba su cobertura.\n",
    "\n",
    "**Nota 3**: Entregad el paquete como un único archivo .zip que contenga sólo el código en el Registro de Evaluación Continua. **El código de Python tendrá que estar escrito en ficheros planos de Python.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1uc6Rcurf4_qlh6Q485-54Sfg6jcKXzwF",
     "timestamp": 1664790160357
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
