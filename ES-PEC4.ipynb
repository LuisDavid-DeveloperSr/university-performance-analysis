{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db062a6",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"https://www.uoc.edu/portal/system/modules/edu.uoc.presentations/resources/img/branding/logo-uoc-default.png\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">22.403 · Programación para la ciencia de datos</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Grado en Ciencia de Datos Aplicada</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd47c74",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "Programación para la ciencia de datos - PEC4\n",
    "============================\n",
    "\n",
    "En este Notebook encontraréis el ejercicio que supone la cuarta y última actividad de evaluación continuada (PEC) de la asignatura. Esta PEC intenta presentaros un pequeño proyecto en el cual debéis resolver diferentes ejercicios, que  engloba muchos de los conceptos cubiertos durante la asignatura. \n",
    "\n",
    "El objetivo de este ejercicio será desarrollar un **paquete de Python** fuera del entorno de Notebooks, que nos permita resolver el problema dado. \n",
    "Trabajaréis en archivos Python planos `.py`. Éste tendrá que incluir el correspondiente código organizado lógicamente (separado por módulos, organizados por funcionalidad,...), la documentación del código (*docstrings*) y tests. Además, tendréis que incluir los correspondientes archivos de documentación de alto nivel (`README`) así como los archivos de licencia y dependencias (`requirements.txt`) comentados en la teoría.\n",
    "\n",
    "Hacer un `setup.py` es opcional, pero si se hace se valorará positivamente de cara a la nota de la práctica y del curso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a22412",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "# Rendimiento de los estudiantes universitarios en Cataluña"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208ccb7",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "## Descripción del Dataset: Rendimiento de los estudiantes universitarios en Cataluña\n",
    "\n",
    "El conjunto de datos recoge los principales indicadores vinculados a la medida del rendimiento académico de los estudiantes, como son las tasas de rendimiento, de graduación, de eficiencia y de abandono. Los datos han sido descargados desde el siguiente enlace: \n",
    "* https://recercaiuniversitats.gencat.cat/ca/03_ambits_dactuacio/xifres/docencia/Rendiment-dels-estudiants/\n",
    "\n",
    "\n",
    "Se trabajará con dos datasets principales:\n",
    "\n",
    "### 1. Tasa de rendimiento (rendiment_estudiants.xlsx)\n",
    "Para un determinado curso, es el cociente entre el número de créditos superados respecto al número de créditos matriculados en los estudios de grados y másteres.\n",
    "\n",
    "* En este cálculo solo se tienen en cuenta los **créditos ordinarios**, que son los propios de un estudio.\n",
    "* Se excluyen los créditos reconocidos, los adaptados y los transferidos de otros planes de estudios.\n",
    "\n",
    "### 2. Tasa de abandono (taxa_abandonament.xlsx)\n",
    "Para un determinado curso, es la proporción de estudiantes de grado o máster que abandonan el Sistema Universitario Catalán (SUC) en el primer curso sobre el total de nuevo acceso de aquel curso.\n",
    "\n",
    "* Se establece que el estudiante ha abandonado el SUC si no se matricula en el próximo curso en ninguna de las universidades catalanas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3a984d",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "## Proyecto Python, funcionalidad\n",
    "\n",
    "Para hacer la entrega más fácil y homogénea os pedimos que organicéis el código de tal manera que **desde el fichero principal retorne todas las respuestas que se os pida en la PEC** haciendo uso de funciones que tendréis que definir en módulos.  Para ello, en cada ejercicio os indicaremos el formato que tiene que tener cada respuesta, de tal manera que ejecutando `main.py` se vaya respondiendo a toda la PEC.\n",
    "\n",
    "Por defecto, `main.py` debe ejecutar todas las funciones de la PEC mostrando cómo funcionan pero también debe permitir ejecutarlas una a una si se desea (entendiendo que para ejecutar la segunda se tiene que haber ejecutado la primera, etc). Debéis documentarlo todo muy bien en el *README* para que el profesor pueda ejecutar el código sin problemas y sin dudas. En el README también tendréis que indicar cómo instalar el proyecto, cómo ejecutarlo, generar la documentación, ejecutar los tests y la cobertura, comprobar el cumplimiento de las reglas de estilos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b81ac1",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "# Ejercicio 1. Load dataset y EDA\n",
    "\n",
    "* Crear una función que acepte una ruta de archivo como argumento opcional. Si se proporciona la ruta, la función debe leer el fichero correspondiente. Si no se proporciona ninguna entrada, la función debe preguntar al usuario qué dataset de los dos disponibles desea cargar. Esta función se deberá reutilizar en los siguientes ejercicios.\n",
    "\n",
    "* Exploración del dataset. Para el dataset que el usuario seleccione, se debe:\n",
    "\n",
    "    * 1.1. Mostrar las 5 primeras filas.\n",
    "    * 1.2. Mostrar las columnas del dataframe.\n",
    "    * 1.3. Mostrar la información (*info()*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017fdf4",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "# Ejercicio 2: limpieza de los datos y filtrado\n",
    "\n",
    "Se pretende hacer un análisis de los dos datasets que se proporcionan. Para ello, lo primero que queremos hacer es limpiar y unir los datasets. Como habrás podido comprobar en el EDA, los datasets tienen estructuras similares pero no completamente iguales. Los objetivos de este ejercicio son:\n",
    "* Homogeneizar ambos datasets: implica que las columnas tengan el mismo nombre y que los datos que se muestren tengan el mismo origen\n",
    "* Actualmente cada línea de datos muestra la información de un estudio en concreto por curso académico y sexo (para diferenciar los resultados entre hombres y mujeres). Para simplificar el análisis posterior, queremos agrupar los estudios por rama (Branca), de tal forma que tengamos una línea por curso académico y rama de estudio, donde la tasa de rendimiento y el % de abandono sea la media de los estudios que contienen esa rama. \n",
    "* Finalmente queremos crear un dataset fusionado a partir de ambos datasets\n",
    "\n",
    "Por lo tanto, este ejercicio debe:\n",
    "\n",
    "* 2.1. Renombrar las columnas del dataset taxa_abandonament.xlsx para que coincida con el dataset rendiment_estudiants.xlsx\n",
    "* 2.2. Eliminar las columnas de \"Universitat\", \"Unitat\" en ambos dataframes, y también \"Crèdits ordinaris superats\" y \"Crèdits ordinaris matriculats\" en el caso del dataset de rendimiento.\n",
    "* 2.3. Crear y aplicar a los datasets una función que agrupe todas las filas que compartan las mismas características (excepto el nombre del estudio) para ambos datasets. La función debe devolver un nuevo dataset con:\n",
    "    * Una fila por cada combinación únicas de las columnas ['Curs Acadèmic', 'Tipus universitat', 'Sigles', 'Tipus Estudi', 'Branca', 'Sexe', 'Integrat S/N']\n",
    "    * Una columna con el rendimiento medio, en el caso del dataset de rendimiento y con la tasa media de abandono en el caso del dataset de abandono.\n",
    "* 2.4. Crear una función para fusionar ambos datasets. El dataset resultante solo debe contener las filas coincidentes entre ambos datasets. A partir de ahora utilizaréis este datasets en los ejercicios futuros. \n",
    "\n",
    "*Nota*: Para agrupar los datasets podéis utilizar el método _groupby_ de pandas, y para fusionar ambos datasets, el método _merge_ con la propiedad _inner_. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1a102",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "# Ejercicio 3: Análisis Visual de Tendencias Temporales\n",
    "\n",
    "#### 3.1. Generación de Gráficos de Series Temporales\n",
    "\n",
    "Crear una función que genere visualizaciones de series temporales con las siguientes características:\n",
    "- Crear **dos gráficos** (subplots) en una misma figura:\n",
    "  - **Gráfico 1**: Evolución del % de Abandonamiento por curso académico\n",
    "  - **Gráfico 2**: Evolución de la Tasa de Rendimiento por curso académico\n",
    "  \n",
    "- Cada gráfico debe mostrar:\n",
    "  - Una línea diferente para cada rama de estudio (_Branca_)\n",
    "  - Leyenda identificando cada rama\n",
    "  - Grid para facilitar la lectura\n",
    "  - Etiquetas de ejes apropiadas\n",
    "  - Título descriptivo\n",
    "\n",
    "**Visualización:**\n",
    "- Tamaño de figura recomendado: 14x10 pulgadas\n",
    "- Utilizar colores distintos para cada rama (sugerencia: `plt.cm.tab10`)\n",
    "- Rotar etiquetas del eje X si es necesario para mejor legibilidad\n",
    "\n",
    "#### 3.2. Guardar las Visualizaciones\n",
    "\n",
    "- Guardar la figura generada en el directorio `src/img/`\n",
    "- Nombre del archivo: `evolucion_nombre_alumno.png`\n",
    "- Resolución recomendada: 300 dpi\n",
    "- Crear el directorio si no existe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14ae48",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "# Ejercicio 4: Análisis estadístico automatizado\n",
    "\n",
    "\n",
    "En este ejercicio, crearás una función llamada `analyze_dataset()` que se encargará de realizar un análisis estadístico completo del dataset fusionado que obtuviste en el ejercicio 2. El objetivo es calcular diferentes métricas y estadísticas que nos permitan entender mejor el comportamiento del rendimiento y el abandono universitario, y guardar todos estos resultados en un archivo JSON bien estructurado.\n",
    "\n",
    "**Estructura del análisis JSON:**\n",
    "\n",
    "El archivo JSON que debes generar (`src/report/analisi_estadistic.json`) debe contener los siguientes apartados. Observa cómo está organizado en secciones lógicas que van de lo general (metadata y estadísticas globales) a lo específico (análisis por rama). Podrás ver un ejemplo de la estructura en (`examples/analisi_estadistic_example.json`) (*Nota: Los valores del ejemplo no son los correctos*).\n",
    "\n",
    "### 4.1. Sección Metadata:\n",
    "   \n",
    "   Esta sección debe contener información básica sobre el análisis que estás realizando. Piensa en ella como la \"ficha técnica\" de tu análisis:\n",
    "   \n",
    "   - **fecha_analisis**: La fecha actual en formato ISO (YYYY-MM-DD). Usa `datetime.now().strftime(\"%Y-%m-%d\")` para obtenerla automáticamente.\n",
    "   - **num_registros**: El número total de registros en tu dataset fusionado. Simplemente usa `len(merged_df)`.\n",
    "   - **periodo_temporal**: Una lista ordenada con todos los cursos académicos únicos que aparecen en tus datos. Puedes obtenerla con `sorted(merged_df['Curs Acadèmic'].unique())`.\n",
    "\n",
    "### 4.2. Estadísticas Globales:\n",
    "   \n",
    "   Aquí calcularás las métricas que resumen el comportamiento general de todo el sistema universitario catalán, sin diferenciar por ramas:\n",
    "   \n",
    "   - **abandono_medio**: La tasa media de abandono en primer curso, calculada como la media de la columna `'% Abandonament a primer curs'`.\n",
    "   - **rendimiento_medio**: La tasa media de rendimiento, calculada como la media de la columna `'Taxa rendiment'`.\n",
    "   - **correlacion_abandono_rendimiento**: Este es un valor muy interesante que nos indica si existe relación entre el abandono y el rendimiento. Para calcularlo, debes usar la correlación de Pearson de scipy:\n",
    "   \n",
    "   ```python\n",
    "   from scipy.stats import pearsonr\n",
    "   \n",
    "   corr, p_value = pearsonr(\n",
    "       merged_df['% Abandonament a primer curs'].dropna(),\n",
    "       merged_df['Taxa rendiment'].dropna()\n",
    "   )\n",
    "   ```\n",
    "   \n",
    "   Una correlación negativa (como -0.68) nos indica que a mayor abandono, menor rendimiento, lo cual tiene sentido intuitivo.\n",
    "\n",
    "### 4.3. Análisis por Rama:\n",
    "   \n",
    "   Esta es la sección más completa del análisis. Para cada rama de estudios (Arts i humanitats, Ciències, Ciències de la salut, etc.), debes calcular:\n",
    "   \n",
    "   - **Estadísticas descriptivas básicas:**\n",
    "     - Media y desviación estándar del porcentaje de abandono\n",
    "     - Media y desviación estándar de la tasa de rendimiento\n",
    "   \n",
    "   - **Detección de tendencias temporales:**\n",
    "     \n",
    "     Aquí es donde aplicarás la regresión lineal para detectar si el abandono en cada rama está mejorando (tendencia decreciente), empeorando (tendencia creciente), o se mantiene estable en el tiempo.\n",
    "     \n",
    "     El proceso es el siguiente:\n",
    "     \n",
    "     a) Primero, agrupa los datos por año académico para cada rama:\n",
    "     ```python\n",
    "     branch_data = merged_df[merged_df['Branca'] == branch]\n",
    "     branch_by_year = branch_data.groupby('Curs Acadèmic').agg({\n",
    "         '% Abandonament a primer curs': 'mean'\n",
    "     }).reset_index()\n",
    "     ```\n",
    "     \n",
    "     b) Extrae las listas de años y valores:\n",
    "     ```python\n",
    "     years = branch_by_year['Curs Acadèmic'].tolist()\n",
    "     valores_abandono = branch_by_year['% Abandonament a primer curs'].tolist()\n",
    "     ```\n",
    "     \n",
    "     c) Calcula la regresión lineal usando scipy:\n",
    "     ```python\n",
    "     from scipy.stats import linregress\n",
    "     \n",
    "     slope, intercept, r_value, p_value, std_err = linregress(\n",
    "         range(len(years)),  # Posiciones: 0, 1, 2, 3...\n",
    "         valores_abandono\n",
    "     )\n",
    "     ```\n",
    "     \n",
    "     d) Interpreta la pendiente (slope):\n",
    "     - Si `slope > 0.01`: la tendencia es \"creciente\" (el abandono aumenta con el tiempo)\n",
    "     - Si `slope < -0.01`: la tendencia es \"decreciente\" (el abandono disminuye)\n",
    "     - Si está entre -0.01 y 0.01: la tendencia es \"estable\" (sin cambios significativos)\n",
    "\n",
    "### 4.4. Rankings:\n",
    "   \n",
    "   Para terminar el análisis, identifica qué ramas tienen los mejores y peores resultados. Esto es útil para tomar decisiones sobre dónde enfocar recursos o investigar qué están haciendo bien las ramas con mejores resultados:\n",
    "   \n",
    "   - Rama con mejor rendimiento (tasa más alta)\n",
    "   - Rama con peor rendimiento (tasa más baja)\n",
    "   - Rama con mayor abandono (porcentaje más alto)\n",
    "   - Rama con menor abandono (porcentaje más bajo)\n",
    "   \n",
    "   Puedes calcular los rankings ordenando las ramas según cada métrica y tomando el primer/último elemento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992e8c1",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "# Requerimientos del proyecte Python\n",
    "\n",
    "\n",
    "## README, LICENCE, requirements.txt\n",
    "\n",
    "* **README**: Tenéis que añadir el fichero README (README.txt, README.md), que presente el proyecto, la estructura de carpetas, y explique cómo instalarlo y ejecutarlo. También cómo ejecutar los tests, generar la documentación y comprobar el linting. La explicación de cómo se ejecuta dentro de un entorno virtual es opcional.\n",
    "\n",
    "* Incluir el fichero **LICENSE** de la licencia bajo la que se distribuye el código (podéis escoger la que queráis).\n",
    "\n",
    "* **requirements.txt**: fichero de requisitos que contenga la lista de librerías necesarias parar ejecutar el código. Han de ser las librerías propias de este proyecto (no hace falta incluir, aunque se puede, las librerías accesorias para ejecutar los tests, linter, documentación).\n",
    "\n",
    "## Modularidad\n",
    "\n",
    "El código tiene que ser modular, tanto en las funciones que se definan (programación estructurada), como en la organización del código en módulos. Una posibilidad es separar cada ejercicio en un fichero. Otro alumno preferirá que los ficheros de los módulos sean funcionalidades. Típicamente habrá el fichero *main.py*, y este fichero importará los módulos y ejecutará los diferentes ejercicios. La idea es que toda la funcionalidad esté en los módulos, y el fichero *main.py* sirva como punto de entrada para leer las opciones y ejecutar los módulos/ejercicios.\n",
    "\n",
    "## Opciones en la línea de comandos\n",
    "\n",
    "Puedes utilizar directamente la librería *sys*, o bien alguna otra posibilidad (*getopt* o *argparse*, que es la que se utiliza en la solución), tanto da. Lo que se pide es que haya la opción de ayuda (-h, --help), y ejecutar los ejercicios individualmente (*-ex num*). Si pasamos *-ex 5* presupone que se ejecutan del ejercicio 1 al 5, pues los ejercicios son progresivos. Si no pasamos argumentos, se ejecutan todos los ejercicios. Documentar en el *README*.\n",
    "\n",
    "## Documentación\n",
    "\n",
    "\n",
    "Todas las funciones de los ejercicios de esta PEC tendrán que estar debidamente documentadas utilizando docstrings (en el formato que prefiera). Se debe generar la documentación html a partir de los docstrings, que quedará en la carpeta *doc/*. Documentar en *README* y hacer captura de pantalla en la carpeta *screenshots/* de la raíz del proyecto (hay que visualizar el nombre del alumno).\n",
    "\n",
    "## Testing y coverage\n",
    "\n",
    "El código debe contener una o varias suites de test que permitan comprobar que el código funciona correctamente, con un mínimo del 50% de cobertura. Puede hacer un archivo de test para cada ejercicio, contemplando varios casos. Documentar en *README* cómo se ejecutan los tests y cómo se ejecuta la cobertura (**importante**). Realizad una captura de pantalla en la carpeta *screenshots/* de la raíz del proyecto de cómo se ha ejecutado los tests y la cobertura (hay que visualizar el nombre del alumno).\n",
    "\n",
    "## Linter\n",
    "\n",
    "El código debe seguir la guía de estilo de Python (PEP8), exceptuando los casos en los que hacerlo complique la legibilidad del código. Puedes utilizar el linter *pylint*, y puedes poner las excepciones que no te parezcan correctas según tu criterio en el archivo *.pylintrc*, de forma que consigas unos valores superiores a 9 en tus scripts. Documentar en el *README* y hacer captura de pantalla en la carpeta *screenshots/* de la raíz del proyecto (hay que visualizar el nombre del alumno).\n",
    "\n",
    "## Capturas de pantalla\n",
    "\n",
    "Entregarás la carpeta *screenshots/* tal como se ha pedido a lo largo del enunciado.\n",
    "\n",
    "**NOTA**: como siempre, no utilicéis rutas absolutas.\n",
    "\n",
    "**NOTA**: tendréis que entregar un zip con el contenido del proyecto. Típicamente el proyecto contendrá las carpetas *src/*, *src/modules/*, *tests/*, *doc/*, *screenshots/* (aunque algún alumno puede tomar decisiones diferentes). En la raíz del proyecto se espera encontrar los archivos *README* (formato texto o *README.md* formato markdown), *requirements.txt*, *LICENSE*, y quizás algún otro como *.pylintrc*, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7659b",
   "metadata": {
    "number_sections": false
   },
   "source": [
    "# Rúbrica\n",
    "\n",
    "### Funcionalidad (4 p)\n",
    "\n",
    "* **Ejercicio 1 (0,5 p)**\n",
    "* **Ejercicio 2 (0,75 p)**\n",
    "* **Ejercicio 3 (0,75 p)**\n",
    "* **Ejercicio 4 (2,00 p)**\n",
    "\n",
    "### Aspectos formales del proyecto Python (6 p)\n",
    "\n",
    "* **README, LICENCE, requirements.txt (1 p)**\n",
    "* **Modularidad (1 p)**\n",
    "* **Opciones en la línea de comandos (ejecutar los ejercicios individualmente y ayuda). (1 p)**\n",
    "* **Generar documentación (formato html) (1 p)**\n",
    "* **Testing y coverage (1 p)**\n",
    "* **Linter (pylint) (0,50 p)**\n",
    "* **Capturas de pantalla (visualizar el nombre del alumno) (0,50 p)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a0d91",
   "metadata": {
    "number_sections": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "number_sections": false
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
